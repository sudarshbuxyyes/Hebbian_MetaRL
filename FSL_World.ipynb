{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLXU/ttsQkTT7HVnhQU3/w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudarshbuxyyes/Hebbian_MetaRL/blob/main/FSL_World.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade setuptools==65.5.0\n",
        "!pip install learn2learn\n",
        "!pip install import_ipynb\n",
        "!pip install utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YZ9r8cjNDQ-",
        "outputId": "7eb20e49-9eb7-49c9-bcab-6c4b8bdd2afb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: setuptools==65.5.0 in /usr/local/lib/python3.9/dist-packages (65.5.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: learn2learn in /usr/local/lib/python3.9/dist-packages (0.1.7)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from learn2learn) (2.0.0+cu118)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.9/dist-packages (from learn2learn) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from learn2learn) (2.27.1)\n",
            "Requirement already satisfied: gsutil in /usr/local/lib/python3.9/dist-packages (from learn2learn) (5.23)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from learn2learn) (0.15.1+cu118)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from learn2learn) (1.10.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from learn2learn) (4.65.0)\n",
            "Requirement already satisfied: qpth>=0.0.15 in /usr/local/lib/python3.9/dist-packages (from learn2learn) (0.0.15)\n",
            "Requirement already satisfied: gym>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from learn2learn) (0.25.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from gym>=0.14.0->learn2learn) (6.4.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from gym>=0.14.0->learn2learn) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from gym>=0.14.0->learn2learn) (0.0.8)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.1.0->learn2learn) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.1.0->learn2learn) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.1.0->learn2learn) (3.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.1.0->learn2learn) (4.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.1.0->learn2learn) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.1.0->learn2learn) (3.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.1.0->learn2learn) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.1.0->learn2learn) (16.0.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.3.0->learn2learn) (8.4.0)\n",
            "Requirement already satisfied: fasteners>=0.14.1 in /usr/local/lib/python3.9/dist-packages (from gsutil->learn2learn) (0.18)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from gsutil->learn2learn) (1.16.0)\n",
            "Requirement already satisfied: google-reauth>=0.1.0 in /usr/local/lib/python3.9/dist-packages (from gsutil->learn2learn) (0.1.1)\n",
            "Requirement already satisfied: argcomplete>=1.9.4 in /usr/local/lib/python3.9/dist-packages (from gsutil->learn2learn) (3.0.5)\n",
            "Requirement already satisfied: httplib2==0.20.4 in /usr/local/lib/python3.9/dist-packages (from gsutil->learn2learn) (0.20.4)\n",
            "Requirement already satisfied: google-auth[aiohttp]>=2.5.0 in /usr/local/lib/python3.9/dist-packages (from gsutil->learn2learn) (2.17.3)\n",
            "Requirement already satisfied: google-apitools>=0.5.32 in /usr/local/lib/python3.9/dist-packages (from gsutil->learn2learn) (0.5.32)\n",
            "Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.9/dist-packages (from gsutil->learn2learn) (1.7)\n",
            "Requirement already satisfied: monotonic>=1.4 in /usr/local/lib/python3.9/dist-packages (from gsutil->learn2learn) (1.6)\n",
            "Requirement already satisfied: retry-decorator>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from gsutil->learn2learn) (1.1.1)\n",
            "Requirement already satisfied: gcs-oauth2-boto-plugin>=3.0 in /usr/local/lib/python3.9/dist-packages (from gsutil->learn2learn) (3.0)\n",
            "Requirement already satisfied: pyOpenSSL>=0.13 in /usr/local/lib/python3.9/dist-packages (from gsutil->learn2learn) (23.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.9/dist-packages (from httplib2==0.20.4->gsutil->learn2learn) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->learn2learn) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->learn2learn) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->learn2learn) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->learn2learn) (2022.12.7)\n",
            "Requirement already satisfied: rsa==4.7.2 in /usr/local/lib/python3.9/dist-packages (from gcs-oauth2-boto-plugin>=3.0->gsutil->learn2learn) (4.7.2)\n",
            "Requirement already satisfied: boto>=2.29.1 in /usr/local/lib/python3.9/dist-packages (from gcs-oauth2-boto-plugin>=3.0->gsutil->learn2learn) (2.49.0)\n",
            "Requirement already satisfied: oauth2client>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from gcs-oauth2-boto-plugin>=3.0->gsutil->learn2learn) (4.1.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.9/dist-packages (from rsa==4.7.2->gcs-oauth2-boto-plugin>=3.0->gsutil->learn2learn) (0.4.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth[aiohttp]>=2.5.0->gsutil->learn2learn) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth[aiohttp]>=2.5.0->gsutil->learn2learn) (0.2.8)\n",
            "Requirement already satisfied: aiohttp<4.0.0dev,>=3.6.2 in /usr/local/lib/python3.9/dist-packages (from google-auth[aiohttp]>=2.5.0->gsutil->learn2learn) (3.8.4)\n",
            "Requirement already satisfied: pyu2f in /usr/local/lib/python3.9/dist-packages (from google-reauth>=0.1.0->gsutil->learn2learn) (0.1.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.8.0->gym>=0.14.0->learn2learn) (3.15.0)\n",
            "Requirement already satisfied: cryptography<41,>=38.0.0 in /usr/local/lib/python3.9/dist-packages (from pyOpenSSL>=0.13->gsutil->learn2learn) (40.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.1.0->learn2learn) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.1.0->learn2learn) (1.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil->learn2learn) (1.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil->learn2learn) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil->learn2learn) (6.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil->learn2learn) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil->learn2learn) (23.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil->learn2learn) (4.0.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.9/dist-packages (from cryptography<41,>=38.0.0->pyOpenSSL>=0.13->gsutil->learn2learn) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.12->cryptography<41,>=38.0.0->pyOpenSSL>=0.13->gsutil->learn2learn) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import gym\n",
        "from gym import spaces\n",
        "import learn2learn as l2l\n",
        "from learn2learn.data import *\n",
        "import import_ipynb\n",
        "import utils\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "import pickle\n",
        "from queue import Queue\n",
        "from threading import Thread\n",
        "from numpy.distutils.misc_util import is_sequence\n",
        "import threading\n",
        "# from stable_baselines3 import PPO,DQN,A2C,SAC\n",
        "import gym\n",
        "from gym import spaces,Env"
      ],
      "metadata": {
        "id": "ffZekOB_M74F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Controller():\n",
        "    def __init__(self,parent=None):\n",
        "        self.parent=parent\n",
        "    def act(self,world_state):\n",
        "        perceived_state=self.parent.perception.perceive_state(world_state)\n",
        "        if self.parent.debug: print(perceived_state)\n",
        "        if self.parent.use_memory: self.parent.memory.add_percept(perceived_state,self.parent.time)\n",
        "        actor_state=self.parent.actor.percept_to_state(perceived_state)\n",
        "        if self.parent.use_memory: actor_state=self.parent.actor.augment_state(actor_state)\n",
        "        if self.parent.debug: print('actor_state:',actor_state)\n",
        "        if self.parent.use_memory: self.parent.memory.update_next_state(actor_state,self.parent.time-1)\n",
        "        action=self.parent.actor.call_model(actor_state)\n",
        "        if self.parent.debug: print('action:',action)\n",
        "        if self.parent.use_memory: action_to_store=self.parent.perception.action_perceptual(action)\n",
        "        if self.parent.use_memory: \n",
        "            intrinsic_reward=self.parent.actor.intrinsic_reward(perceived_state,action_to_store,actor_state)\n",
        "        # if self.parent.use_memory: self.parent.memory.update_reward_sar(intrinsic_reward,self.parent.time-1)\n",
        "        if self.parent.use_memory: self.parent.memory.update_reward_sar(intrinsic_reward,self.parent.time)\n",
        "        if self.parent.use_memory: self.parent.memory.update_action_perceptual(action_to_store,self.parent.time)\n",
        "        if self.parent.use_memory: self.parent.memory.add_state_action(actor_state,action_to_store,self.parent.time)\n",
        "        world_action=self.parent.perception.action_to_world(action)\n",
        "        if self.parent.limit_memory: self.parent.memory.pop()\n",
        "        return world_action\n",
        "    def reward(self,world_reward):\n",
        "        reward=self.parent.perception.perceive_reward(world_reward)\n",
        "        if self.parent.use_memory: self.parent.memory.update_reward_perceptual(reward,self.parent.time-1)\n",
        "        if self.parent.use_memory: reward_sar=self.parent.actor.compute_reward(reward)\n",
        "        if self.parent.use_memory: self.parent.memory.update_reward_sar(reward_sar,self.parent.time-1)\n",
        "        if self.parent.limit_memory: self.parent.memory.pop() \n",
        "        return reward\n"
      ],
      "metadata": {
        "id": "hR3kwiz7QoW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Memory():\n",
        "    def __init__(self,parent=None):\n",
        "        self.parent=parent\n",
        "        self.clear()\n",
        "        self.limit_perceptual=None\n",
        "        self.limit_sar=None\n",
        "    def pop(self):\n",
        "        psize=self.limit_perceptual\n",
        "        M=self.perceptual_memory\n",
        "        if psize!=None: \n",
        "            for t in [t for t in M if t<self.parent.time-psize]: M.pop(t)\n",
        "        S=self.sar_memory\n",
        "        ssize=self.limit_sar\n",
        "        if ssize!=None: \n",
        "            for t in [t for t in S if t<self.parent.time-ssize]: S.pop(t)\n",
        "    def clear(self):\n",
        "        self.perceptual_memory={}\n",
        "        self.sar_memory={}\n",
        "    def add_percept(self,perceived_state,time):\n",
        "        self.perceptual_memory[time]=perceived_state\n",
        "        if self.parent.debug: print('add_percept:',self.perceptual_memory)\n",
        "    def update_next_state(self,actor_state,time):\n",
        "        if time in self.sar_memory: self.sar_memory[time]['next_state']=actor_state\n",
        "        else: self.sar_memory[time]={'next_state':actor_state}\n",
        "        if self.parent.debug: print('update_next_state:',self.sar_memory)\n",
        "    def update_action_perceptual(self,action,time):\n",
        "        self.perceptual_memory[time]['action']=action\n",
        "        if self.parent.debug: print('update_action_perceptual:',self.perceptual_memory)\n",
        "    def add_state_action(self,actor_state,action,time):\n",
        "        if time in self.sar_memory: \n",
        "            self.sar_memory[time]['state']=actor_state\n",
        "            self.sar_memory[time]['action']=action\n",
        "        else: self.sar_memory[time]={'state':actor_state,'action':action}\n",
        "        if self.parent.debug: print('add_state_action:',self.sar_memory)\n",
        "    def update_reward_perceptual(self,reward,time):\n",
        "        self.perceptual_memory[time]['reward']=reward\n",
        "        if self.parent.debug: print('update_reward_perceptual:',self.perceptual_memory)\n",
        "    def update_reward_sar(self,reward,time):\n",
        "        if time in self.sar_memory:\n",
        "            if 'reward' in self.sar_memory[time]:self.sar_memory[time]['reward']+=reward\n",
        "            else: self.sar_memory[time]['reward']=reward\n",
        "        else:\n",
        "            self.sar_memory[time]={'reward':reward}\n",
        "        if self.parent.debug: print('update_reward_sar:',self.sar_memory)"
      ],
      "metadata": {
        "id": "2iTYx8ZlQtGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Perception():\n",
        "    def __init__(self,parent=None):\n",
        "        self.parent=parent\n",
        "    def perceive_state(self,world_state):\n",
        "        if type(world_state)==dict: return world_state\n",
        "        else: return {'percept':world_state}\n",
        "    def action_to_world(self,action):\n",
        "        return action\n",
        "    def action_perceptual(self,action):\n",
        "        return action\n",
        "    def perceive_reward(self,reward):\n",
        "        return reward"
      ],
      "metadata": {
        "id": "C7kdS6vRQ2rj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Actor():\n",
        "    def __init__(self,parent=None,model=None):\n",
        "        self.parent=parent\n",
        "        self.model=model\n",
        "        self.default_action='default_action'\n",
        "        self.intrinsic_reward_value=0\n",
        "    def percept_to_state(self,perceived_state):\n",
        "        return perceived_state['percept']\n",
        "    def augment_state(self,state):\n",
        "        return state\n",
        "    def call_model(self,actor_state):\n",
        "        return self.default_action\n",
        "    def compute_reward(self,reward):\n",
        "        return reward\n",
        "    def intrinsic_reward(self,precept,action,state):\n",
        "        return self.intrinsic_reward_value"
      ],
      "metadata": {
        "id": "B9Qn5TDj82E8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AIAgent():\n",
        "    def __init__(self,controller=None,perception=None,memory=None,actor=None):\n",
        "        if controller is not None: self.controller=controller\n",
        "        else: self.controller=Controller(parent=self)\n",
        "        if perception is not None: self.perception=perception\n",
        "        else: self.perception=Perception(parent=self)\n",
        "        if memory is not None: self.memory=memory\n",
        "        else: self.memory=Memory(parent=self)\n",
        "        if actor is not None: self.actor=actor\n",
        "        else: self.actor=Actor(parent=self)\n",
        "        self.time=0\n",
        "        self.ep=[]\n",
        "        # self.controller.parent=self\n",
        "        # self.perception.parent=self\n",
        "        # self.memory.parent=self\n",
        "        # self.actor.parent=self\n",
        "        self.debug=False\n",
        "        self.use_memory=True\n",
        "        self.limit_memory=False\n",
        "    def act(self,world_state):\n",
        "        world_action = self.controller.act(world_state)\n",
        "        # check to see if network needs training - TBDesigned\n",
        "        self.time+=1\n",
        "        return world_action\n",
        "    def reward(self,world_reward):\n",
        "        return self.controller.reward(world_reward)\n",
        "    def episode(self):\n",
        "        return self.controller.episode()\n",
        "    def begin(self,state=None):\n",
        "        ## TBD may need to do more - both episode and time may be needed and episode reset\n",
        "        self.ep+=[self.time]\n",
        "    def clear(self):\n",
        "        self.memory.clear()"
      ],
      "metadata": {
        "id": "9kgTA7vRQKAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KShotLoader():\n",
        "    def __init__(self,myds,num_tasks=1000,shots=2,ways=2,classes=None):\n",
        "        self.shots = shots\n",
        "        self.ways = ways\n",
        "        self.myMds = l2l.data.MetaDataset(myds)\n",
        "        if classes == None:\n",
        "            n_classes = len(set(myds.labels))\n",
        "            classes = [i for i in range(n_classes)]\n",
        "        self.my_tasks = l2l.data.TaskDataset(self.myMds, task_transforms=[\n",
        "                                l2l.data.transforms.FilterLabels(self.myMds,classes),\n",
        "                                l2l.data.transforms.NWays(self.myMds,ways),\n",
        "                                l2l.data.transforms.KShots(self.myMds,2*shots),\n",
        "                                l2l.data.transforms.LoadData(self.myMds),\n",
        "                                l2l.data.transforms.RemapLabels(self.myMds),\n",
        "                                l2l.data.transforms.ConsecutiveLabels(self.myMds)\n",
        "                                ],num_tasks=num_tasks)\n",
        "    def get_task(self):\n",
        "        data,labels = self.my_tasks.sample()\n",
        "        adaptation_indices = np.zeros(data.size(0), dtype=bool)\n",
        "        adaptation_indices[np.arange(self.shots*self.ways) * 2] = True\n",
        "        evaluation_indices = torch.from_numpy(~adaptation_indices)\n",
        "        adaptation_indices = torch.from_numpy(adaptation_indices)\n",
        "        adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
        "        evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
        "        d_train = (adaptation_data,adaptation_labels)\n",
        "        d_test = (evaluation_data,evaluation_labels)\n",
        "        return d_train, d_test"
      ],
      "metadata": {
        "id": "QOdQ1G25M0uU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBQJvyrRLzYk"
      },
      "outputs": [],
      "source": [
        "class FSLWorld():\n",
        "    def __init__(self,meta_train_ds,meta_test_ds,n_classes):\n",
        "        self.meta_train_ds=meta_train_ds\n",
        "        self.meta_test_ds=meta_test_ds\n",
        "        self.action_space=spaces.Discrete(n_classes)\n",
        "        self.obs_dim=self.meta_train_ds[0][0].shape[-1]\n",
        "        high = np.inf*np.ones(self.obs_dim)\n",
        "        low = -high\n",
        "        self.observation_space=spaces.Box(high=high,low=low)\n",
        "    def run(self,agent=None,n_episodes=10,n_tasks_train=25,n_tasks_test=50):\n",
        "        if 'training' not in agent.__dict__: agent.training=True\n",
        "        for episode in range(n_episodes):\n",
        "            agent.begin()\n",
        "            count=0\n",
        "            for tid in range(n_tasks_train):\n",
        "                tot_rew=0\n",
        "                meta_train_kloader=KShotLoader(self.meta_train_ds,shots=5,ways=5)\n",
        "                d_train,d_test=meta_train_kloader.get_task()\n",
        "                train_ds = utils.MyDS(d_train[0],d_train[1])\n",
        "                train_ds=[(s.unsqueeze(0),l.unsqueeze(0)) for s,l in train_ds]\n",
        "                for sample,label in train_ds:\n",
        "                    count+=1\n",
        "                    done=(count==len(train_ds))\n",
        "                    action=agent.act(sample)\n",
        "                    reward=(self.accuracy(action,label),{'label':label})\n",
        "                    agent.reward((reward[0],done,reward[1]))\n",
        "                    tot_rew+=reward[0]\n",
        "                if 'end' in dir(agent): agent.end()\n",
        "                print('episode,task: ',episode,tid,'avg reward: ',tot_rew/len(train_ds))\n",
        "        agent.set_training(False)\n",
        "        print('Training Over')\n",
        "        agent.begin()\n",
        "        for tid in range(n_tasks_test):\n",
        "            test_rew=0\n",
        "            meta_test_kloader=KShotLoader(self.meta_test_ds,shots=5,ways=5)\n",
        "            d_train,d_test=meta_test_kloader.get_task()\n",
        "            test_ds = utils.MyDS(d_test[0],d_test[1])\n",
        "            test_ds=[(s.unsqueeze(0),l.unsqueeze(0)) for s,l in test_ds]\n",
        "            for sample,label in test_ds:\n",
        "                action=agent.act(sample)\n",
        "                reward=(self.accuracy(action,label),{})\n",
        "                agent.reward(reward)\n",
        "                test_rew+=reward[0]\n",
        "            print(f'Test {tid} Over; Accuracy: ',test_rew/len(test_ds))\n",
        "    def accuracy(self,action,label):\n",
        "        if (type(action)==np.ndarray): action=action[-1]\n",
        "        if action==label[-1]: return 1\n",
        "        else: return 0"
      ]
    }
  ]
}