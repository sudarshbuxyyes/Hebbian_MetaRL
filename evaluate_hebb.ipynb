{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMp8U24VVu2qss5skOecQHD"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install import_ipynb --quiet\n",
        "# !git clone https://github.com/sudarshbuxyyes/Hebbian_MetaRL.git\n",
        "# %cd Hebbian_MetaRL"
      ],
      "metadata": {
        "id": "d_HmURJZe-OO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import torch\n",
        "import numpy as np\n",
        "import import_ipynb\n",
        "# import pybullet_envs\n",
        "from gym.spaces import Discrete, Box\n",
        "from gym import wrappers as w\n",
        "import pickle\n",
        "import argparse\n",
        "import sys\n"
      ],
      "metadata": {
        "id": "GAbBqLePe3i4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from hebbian_weights_update import *\n",
        "from policies import MLP_heb, CNN_heb\n",
        "from wrapper import ScaledFloatFrame"
      ],
      "metadata": {
        "id": "VDCZMljTf7XB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_hebb(hebb_rule : str, environment : str, init_weights = 'uni', render = True , *evolved_parameters: [np.array]) -> None:\n",
        "    \"\"\"\n",
        "    Copypasta function from fitness_functions::fitness_hebb\n",
        "    It adds rendering of the environment and prints the cumulative episodic reward\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    def weights_init(m):\n",
        "        if isinstance(m, torch.nn.Linear):\n",
        "            if init_weights == 'xa_uni':  \n",
        "                torch.nn.init.xavier_uniform(m.weight.data, 0.3)\n",
        "            elif init_weights == 'sparse':  \n",
        "                torch.nn.init.sparse_(m.weight.data, 0.8)\n",
        "            elif init_weights == 'uni':  \n",
        "                torch.nn.init.uniform_(m.weight.data, -0.1, 0.1)\n",
        "            elif init_weights == 'normal':  \n",
        "                torch.nn.init.normal_(m.weight.data, 0, 0.024)\n",
        "            elif init_weights == 'ka_uni':  \n",
        "                torch.nn.init.kaiming_uniform_(m.weight.data, 3)\n",
        "            elif init_weights == 'uni_big':\n",
        "                torch.nn.init.uniform_(m.weight.data, -1, 1)\n",
        "            elif init_weights == 'xa_uni_big':\n",
        "                torch.nn.init.xavier_uniform(m.weight.data)\n",
        "            elif init_weights == 'default' or init_weights == None:\n",
        "                pass\n",
        "            \n",
        "    # Unpack evolved parameters\n",
        "    try: \n",
        "        hebb_coeffs, initial_weights_co = evolved_parameters\n",
        "    except: \n",
        "        hebb_coeffs = evolved_parameters[0]\n",
        "            \n",
        "    # Intial weights co-evolution flag:\n",
        "    coevolve_init = True if init_weights == 'coevolve' else False\n",
        "\n",
        "    with torch.no_grad():\n",
        "                    \n",
        "        # Load environment\n",
        "        try: env = gym.make(environment, verbose = 0)\n",
        "        except: env = gym.make(environment)\n",
        "                        \n",
        "        if environment[-12:-6] == 'Bullet' and render:\n",
        "            env.render()  # bullet envs            \n",
        "\n",
        "        # Check if selected env is pixel or state-vector \n",
        "        if len(env.observation_space.shape) == 3:     # Pixel-based environment\n",
        "            pixel_env = True\n",
        "            env = w.ResizeObservation(env, 84)        # Resize and normilise input   \n",
        "            env = ScaledFloatFrame(env)\n",
        "            input_channels = 3\n",
        "        elif len(env.observation_space.shape) == 1:   # State-based environment (only valid for with a 'Box' observational space)\n",
        "            pixel_env = False\n",
        "            input_dim = env.observation_space.shape[0]\n",
        "            \n",
        "        # Determine action space dimension\n",
        "        if isinstance(env.action_space, Box):\n",
        "            action_dim = env.action_space.shape[0]\n",
        "        elif isinstance(env.action_space, Discrete):\n",
        "            action_dim = env.action_space.n\n",
        "        else:\n",
        "            raise ValueError('Only Box and Discrete action spaces supported')\n",
        "        \n",
        "        # Initialise policy network: A simple MLP for state-vector environments and a CNN+MLP for pixel-based environments\n",
        "        if pixel_env == True: \n",
        "            p = CNN_heb(input_channels, action_dim)      \n",
        "        else:\n",
        "            p = MLP_heb(input_dim, action_dim)          \n",
        "        \n",
        "        # Initialise weights of the policy network with an specific distribution or with the co-evolved weights\n",
        "        if coevolve_init:\n",
        "            torch.nn.utils.vector_to_parameters( torch.tensor (initial_weights_co, dtype=torch.float32 ),  p.parameters() )\n",
        "        else:       \n",
        "            p.apply(weights_init)\n",
        "             # Load CNN paramters\n",
        "            if pixel_env:\n",
        "                cnn_weights1 = initial_weights_co[:162]\n",
        "                cnn_weights2 = initial_weights_co[162:]\n",
        "                list(p.parameters())[0].data = torch.tensor(cnn_weights1.reshape((6,3,3,3))).float()\n",
        "                list(p.parameters())[1].data = torch.tensor(cnn_weights2.reshape((8,6,5,5))).float()\n",
        "        p = p.float()\n",
        "        \n",
        "        # Unpack network's weights\n",
        "        if pixel_env:\n",
        "            weightsCNN1, weightsCNN2, weights1_2, weights2_3, weights3_4 = list(p.parameters())\n",
        "        else:\n",
        "            weights1_2, weights2_3, weights3_4 = list(p.parameters())\n",
        "            \n",
        "        \n",
        "        # Convert weights to numpy so we can JIT them with Numba\n",
        "        weights1_2 = weights1_2.detach().numpy()\n",
        "        weights2_3 = weights2_3.detach().numpy()\n",
        "        weights3_4 = weights3_4.detach().numpy()\n",
        "        \n",
        "        observation = env.reset() \n",
        "        if pixel_env: observation = np.swapaxes(observation,0,2) #(3, 84, 84)       \n",
        "\n",
        "        # Burnout phase for the bullet quadruped so it starts off from the floor\n",
        "        if environment == 'AntBulletEnv-v0':\n",
        "            action = np.zeros(8)\n",
        "            for _ in range(40):\n",
        "                __ = env.step(action)        \n",
        "        \n",
        "        # normalised_weights = True\n",
        "        normalised_weights = False if environment[-12:-6] == 'Bullet' else True\n",
        "\n",
        "        neg_count = 0\n",
        "        rew_ep = 0\n",
        "        t = 0\n",
        "        while True:\n",
        "            \n",
        "            o0, o1, o2, o3 = p([observation])\n",
        "            o0 = o0.numpy()\n",
        "            o1 = o1.numpy()\n",
        "            o2 = o2.numpy()\n",
        "            \n",
        "            # Adding bounds to the action space\n",
        "            if environment == 'CarRacing-v0':\n",
        "                action = np.array([ torch.tanh(o3[0]), torch.sigmoid(o3[1]), torch.sigmoid(o3[2]) ]) \n",
        "                o3 = o3.numpy()\n",
        "            elif environment[-12:-6] == 'Bullet':\n",
        "                o3 = torch.tanh(o3).numpy()\n",
        "                action = o3\n",
        "            else: \n",
        "                if isinstance(env.action_space, Box):\n",
        "                    action = o3.numpy()\n",
        "                    action = np.clip(action, env.action_space.low, env.action_space.high)                           \n",
        "                elif isinstance(env.action_space, Discrete):\n",
        "                    action = np.argmax(o3).numpy()\n",
        "                o3 = o3.numpy()\n",
        "            \n",
        "            # Environment simulation step\n",
        "            observation, reward, done, info  = env.step(action)  \n",
        "            if environment == 'AntBulletEnv-v0':\n",
        "                reward = env.unwrapped.rewards[1] # Distance walked\n",
        "            rew_ep += reward\n",
        "            \n",
        "            # Render\n",
        "            if environment[-12:-6] != 'Bullet' and render:\n",
        "                env.render('human') # Gym envs\n",
        "            \n",
        "            if pixel_env: observation = np.swapaxes(observation,0,2) #(3, 84, 84)\n",
        "                            \n",
        "            # Breaking conditions\n",
        "            if environment == 'CarRacing-v0':\n",
        "                neg_count = neg_count+1 if reward < 0.0 else 0\n",
        "                if (done or neg_count > 20):\n",
        "                    break\n",
        "            elif environment[-12:-6] == 'Bullet':\n",
        "                if t > 200:\n",
        "                    neg_count = neg_count+1 if reward < 0.0 else 0\n",
        "                    if (done or neg_count > 30):\n",
        "                        break\n",
        "            else:\n",
        "                if done:\n",
        "                    break\n",
        "            t += 1\n",
        "            \n",
        "            #### Episodic/Intra-life hebbian update of the weights\n",
        "            if hebb_rule == 'A': \n",
        "                weights1_2, weights2_3, weights3_4 = hebbian_update_A(hebb_coeffs, weights1_2, weights2_3, weights3_4, o0, o1, o2, o3)\n",
        "            elif hebb_rule == 'AD':\n",
        "                weights1_2, weights2_3, weights3_4 = hebbian_update_AD(hebb_coeffs, weights1_2, weights2_3, weights3_4, o0, o1, o2, o3)\n",
        "            elif hebb_rule == 'AD_lr':\n",
        "                weights1_2, weights2_3, weights3_4 = hebbian_update_AD_lr(hebb_coeffs, weights1_2, weights2_3, weights3_4, o0, o1, o2, o3)\n",
        "            elif hebb_rule == 'ABC':\n",
        "                weights1_2, weights2_3, weights3_4 = hebbian_update_ABC(hebb_coeffs, weights1_2, weights2_3, weights3_4, o0, o1, o2, o3)\n",
        "            elif hebb_rule == 'ABC_lr':\n",
        "                weights1_2, weights2_3, weights3_4 = hebbian_update_ABC_lr(hebb_coeffs, weights1_2, weights2_3, weights3_4, o0, o1, o2, o3)\n",
        "            elif hebb_rule == 'ABCD':\n",
        "                weights1_2, weights2_3, weights3_4 = hebbian_update_ABCD(hebb_coeffs, weights1_2, weights2_3, weights3_4, o0, o1, o2, o3)\n",
        "            elif hebb_rule == 'ABCD_lr':\n",
        "                weights1_2, weights2_3, weights3_4 = hebbian_update_ABCD_lr_D_in(hebb_coeffs, weights1_2, weights2_3, weights3_4, o0, o1, o2, o3)\n",
        "            elif hebb_rule == 'ABCD_lr_D_out':\n",
        "                weights1_2, weights2_3, weights3_4 = hebbian_update_ABCD_lr_D_out(hebb_coeffs, weights1_2, weights2_3, weights3_4, o0, o1, o2, o3)\n",
        "            elif hebb_rule == 'ABCD_lr_D_in_and_out':\n",
        "                weights1_2, weights2_3, weights3_4 = hebbian_update_ABCD_lr_D_in_and_out(hebb_coeffs, weights1_2, weights2_3, weights3_4, o0, o1, o2, o3)\n",
        "            else:\n",
        "                raise ValueError('The provided Hebbian rule is not valid')\n",
        "\n",
        "\n",
        "            # Normalise weights per layer\n",
        "            if normalised_weights == True:\n",
        "                (a, b, c) = (0, 1, 2) if not pixel_env else (2, 3, 4)\n",
        "                list(p.parameters())[a].data /= list(p.parameters())[a].__abs__().max()\n",
        "                list(p.parameters())[b].data /= list(p.parameters())[b].__abs__().max()\n",
        "                list(p.parameters())[c].data /= list(p.parameters())[c].__abs__().max()\n",
        "            \n",
        "        env.close()\n",
        "        \n",
        "        print('\\n Episode cumulative rewards ', int(rew_ep))\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "# def main(argv):\n",
        "#     parser = argparse.ArgumentParser()\n",
        "    \n",
        "#     parser.add_argument('--environment', type=str, default='CarRacing-v0', metavar='', help='Gym environment: any OpenAI Gym may be used')\n",
        "#     parser.add_argument('--hebb_rule', type=str,  default = 'ABCD_lr', metavar='', help='Hebbian rule type: A, AD, AD_lr, ABC, ABC_lr, ABCD, ABCD_lr, ABCD_lr_D_out, ABCD_lr_D_in_and_out')    \n",
        "#     parser.add_argument('--init_weights', type=str,  default = 'uni', metavar='', help='Weight initilisation distribution used to sample from at each episode: uni, normal, default, xa_uni, sparse, ka_uni')\n",
        "#     parser.add_argument('--path_hebb', type=str,  default = None, metavar='', help='path to the evolved Hebbian coefficients')\n",
        "#     parser.add_argument('--path_coev', type=str,  default = None, metavar='', help='path to the evolved CNN parameters or the coevolve initial weights')\n",
        "\n",
        "#     args = parser.parse_args()\n",
        "\n",
        "#     hebb_coeffs = torch.load(args.path_hebb)\n",
        "#     coevolved_or_cnn_parameters = torch.load(args.path_coev) if args.path_coev is not None else None    \n",
        "#     init_weights = 'uni' \n",
        "#     render = True\n",
        "    \n",
        "#     # Run the environment\n",
        "#     evaluate_hebb(args.hebb_rule, args.environment, args.init_weights, render, hebb_coeffs, coevolved_or_cnn_parameters)\n",
        "\n"
      ],
      "metadata": {
        "id": "Y9VT8jwzbrG4"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}