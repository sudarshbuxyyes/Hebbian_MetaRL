{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtM3Z3LS2tMnQnvY1nc/U+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install import_ipynb --quiet\n",
        "# !git clone https://github.com/sudarshbuxyyes/Hebbian_MetaRL.git\n",
        "# %cd Hebbian_MetaRL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "d_HmURJZe-OO",
        "outputId": "80c87a3d-39e7-4976-857f-34d888f3f82b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCloning into 'Hebbian_MetaRL'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 16 (delta 4), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (16/16), 8.36 KiB | 503.00 KiB/s, done.\n",
            "/content/Hebbian_MetaRL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "from gym import wrappers as w\n",
        "from gym.spaces import Discrete, Box\n",
        "# import pybullet_envs\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import List, Any\n",
        "import import_ipynb"
      ],
      "metadata": {
        "id": "e_goXh1wmxH2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from policies import MLP_heb, CNN_heb\n",
        "from hebbian_weights_update import *\n",
        "from wrapper import FireEpisodicLifeEnv, ScaledFloatFrame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9ir-NbUm0IB",
        "outputId": "489dfc11-341c-415e-b1ee-feed3f28f1f4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "importing Jupyter notebook from wrapper.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fitness_hebb(hebb_rule : str, environment : str, init_weights = 'uni' , *evolved_parameters: List[np.array]) -> float:\n",
        "    \"\"\"\n",
        "    Evaluate an agent 'evolved_parameters' controlled by a Hebbian network in an environment 'environment' during a lifetime.\n",
        "    The initial weights are either co-evolved (if 'init_weights' == 'coevolve') along with the Hebbian coefficients or randomly sampled at each episode from the 'init_weights' distribution. \n",
        "    Subsequently the weights are updated following the hebbian update mechanism 'hebb_rule'.\n",
        "    Returns the episodic fitness of the agent.\n",
        "    \"\"\"\n",
        "    \n",
        "    def weights_init(m):\n",
        "        if isinstance(m, torch.nn.Linear):\n",
        "            if init_weights == 'xa_uni':  \n",
        "                torch.nn.init.xavier_uniform(m.weight.data, 0.3)\n",
        "            elif init_weights == 'sparse':  \n",
        "                torch.nn.init.sparse_(m.weight.data, 0.8)\n",
        "            elif init_weights == 'uni':  \n",
        "                torch.nn.init.uniform_(m.weight.data, -0.1, 0.1)\n",
        "            elif init_weights == 'normal':  \n",
        "                torch.nn.init.normal_(m.weight.data, 0, 0.024)\n",
        "            elif init_weights == 'ka_uni':  \n",
        "                torch.nn.init.kaiming_uniform_(m.weight.data, 3)\n",
        "            elif init_weights == 'uni_big':\n",
        "                torch.nn.init.uniform_(m.weight.data, -1, 1)\n",
        "            elif init_weights == 'xa_uni_big':\n",
        "                torch.nn.init.xavier_uniform(m.weight.data)\n",
        "            elif init_weights == 'ones':\n",
        "                torch.nn.init.ones_(m.weight.data)\n",
        "            elif init_weights == 'zeros':\n",
        "                torch.nn.init.zeros_(m.weight.data)\n",
        "            elif init_weights == 'default':\n",
        "                pass\n",
        "            \n",
        "    # Unpack evolved parameters\n",
        "    try: \n",
        "        hebb_coeffs, initial_weights_co = evolved_parameters\n",
        "    except: \n",
        "        hebb_coeffs = evolved_parameters[0]\n",
        "\n",
        "    # Intial weights co-evolution flag:\n",
        "    coevolve_init = True if init_weights == 'coevolve' else False\n",
        "    \n",
        "\n",
        "    with torch.no_grad():\n",
        "                    \n",
        "        # Load environment\n",
        "        try:\n",
        "            env = gym.make(environment, verbose = 0)\n",
        "        except:\n",
        "            env = gym.make(environment)\n",
        "            \n",
        "        # env.render()  # bullet envs\n",
        "        \n",
        "        # For environments with several intra-episode lives -eg. Breakout-\n",
        "        try: \n",
        "            if 'FIRE' in env.unwrapped.get_action_meanings():\n",
        "                env = FireEpisodicLifeEnv(env)\n",
        "        except: \n",
        "            pass\n",
        "\n",
        "        # Check if selected env is pixel or state-vector \n",
        "        if len(env.observation_space.shape) == 3:     # Pixel-based environment\n",
        "            pixel_env = True\n",
        "            env = w.ResizeObservation(env, 84)        # Resize and normilise input   \n",
        "            env = ScaledFloatFrame(env)\n",
        "            input_channels = 3\n",
        "        elif len(env.observation_space.shape) == 1:   \n",
        "            pixel_env = False\n",
        "            input_dim = env.observation_space.shape[0]\n",
        "        elif len(env.observation_space.shape) == 0:   \n",
        "            pixel_env = False\n",
        "            input_dim = env.observation_space.n\n",
        "            \n",
        "        # Determine action space dimension\n",
        "        if isinstance(env.action_space, Box):\n",
        "            action_dim = env.action_space.shape[0]\n",
        "        elif isinstance(env.action_space, Discrete):\n",
        "            action_dim = env.action_space.n\n",
        "        else:\n",
        "            raise ValueError('Only Box and Discrete action spaces supported')\n",
        "        \n",
        "        # Initialise policy network: with CNN layer for pixel envs and simple MLP for state-vector envs\n",
        "        if pixel_env == True: \n",
        "            p = CNN_heb(input_channels, action_dim)      \n",
        "        else:\n",
        "            p = MLP_heb(input_dim, action_dim)          \n",
        "        \n",
        "        \n",
        "        # Initialise weights of the policy network with an specific distribution or with the co-evolved weights\n",
        "        if coevolve_init:\n",
        "            nn.utils.vector_to_parameters( torch.tensor (initial_weights_co, dtype=torch.float32 ),  p.parameters() )\n",
        "        else:       \n",
        "            # Randomly sample initial weights from chosen distribution\n",
        "            p.apply(weights_init)\n",
        "            \n",
        "             # Load CNN paramters\n",
        "            if pixel_env:\n",
        "                cnn_weights1 = initial_weights_co[:162]\n",
        "                cnn_weights2 = initial_weights_co[162:]\n",
        "                list(p.parameters())[0].data = torch.tensor(cnn_weights1.reshape((6,3,3,3))).float()\n",
        "                list(p.parameters())[1].data = torch.tensor(cnn_weights2.reshape((8,6,5,5))).float()\n",
        "        p = p.float()\n",
        "        \n",
        "        # Unpack network's weights\n",
        "        if pixel_env:\n",
        "            weightsCNN1, weightsCNN2, weights1_2, weights2_3, weights3_4 = list(p.parameters())\n",
        "        else:\n",
        "            weights1_2, weights2_3, weights3_4 = list(p.parameters())\n",
        "            \n",
        "        \n",
        "        # Convert weights to numpy so we can JIT them with Numba\n",
        "        weights1_2 = weights1_2.detach().numpy()\n",
        "        weights2_3 = weights2_3.detach().numpy()\n",
        "        weights3_4 = weights3_4.detach().numpy()\n",
        "        \n",
        "        observation = env.reset() \n",
        "        if pixel_env: observation = np.swapaxes(observation,0,2) #(3, 84, 84)       \n",
        "\n",
        "        # Burnout phase for the bullet quadruped so it starts off from the floor\n",
        "        if environment == 'AntBulletEnv-v0':\n",
        "            action = np.zeros(8)\n",
        "            for _ in range(40):\n",
        "                __ = env.step(action)        \n",
        "        \n",
        "        # Normalize weights flag for non-bullet envs\n",
        "        normalised_weights = False if environment[-12:-6] == 'Bullet' else True\n",
        "\n",
        "\n",
        "        # Inner loop\n",
        "        neg_count = 0\n",
        "        rew_ep = 0\n",
        "        t = 0\n",
        "        while True:\n",
        "            \n",
        "            # For obaservation ∈ gym.spaces.Discrete, we one-hot encode the observation\n",
        "            if isinstance(env.observation_space, Discrete): \n",
        "                observation = (observation == torch.arange(env.observation_space.n)).float()\n",
        "            \n",
        "            o0, o1, o2, o3 = p([observation])\n",
        "            o0 = o0.numpy()\n",
        "            o1 = o1.numpy()\n",
        "            o2 = o2.numpy()\n",
        "            \n",
        "            # Bounding the action space\n",
        "            if environment == 'CarRacing-v0':\n",
        "                action = np.array([ torch.tanh(o3[0]), torch.sigmoid(o3[1]), torch.sigmoid(o3[2]) ]) \n",
        "                o3 = o3.numpy()\n",
        "            elif environment[-12:-6] == 'Bullet':\n",
        "                o3 = torch.tanh(o3).numpy()\n",
        "                action = o3\n",
        "            else: \n",
        "                if isinstance(env.action_space, Box):\n",
        "                    action = o3.numpy()                        \n",
        "                    action = np.clip(action, env.action_space.low, env.action_space.high)  \n",
        "                elif isinstance(env.action_space, Discrete):\n",
        "                    action = np.argmax(o3).numpy()\n",
        "                o3 = o3.numpy()\n",
        "\n",
        "            \n",
        "            # Environment simulation step\n",
        "            observation, reward, done, info = env.step(action)  \n",
        "            if environment == 'AntBulletEnv-v0': reward = env.unwrapped.rewards[1] # Distance walked\n",
        "            rew_ep += reward\n",
        "            \n",
        "            # env.render('human') # Gym envs\n",
        "            \n",
        "            if pixel_env: observation = np.swapaxes(observation,0,2) #(3, 84, 84)\n",
        "                                       \n",
        "            # Early stopping conditions\n",
        "            if environment == 'CarRacing-v0':\n",
        "                neg_count = neg_count+1 if reward < 0.0 else 0\n",
        "                if (done or neg_count > 20):\n",
        "                    break\n",
        "            elif environment[-12:-6] == 'Bullet':\n",
        "                if t > 200:\n",
        "                    neg_count = neg_count+1 if reward < 0.0 else 0\n",
        "                    if (done or neg_count > 30):\n",
        "                        break\n",
        "            else:\n",
        "                if done:\n",
        "                    break\n",
        "            # else:\n",
        "            #     neg_count = neg_count+1 if reward < 0.0 else 0\n",
        "            #     if (done or neg_count > 50):\n",
        "            #         break\n",
        "            \n",
        "            t += 1\n",
        "            \n",
        "            \n",
        "            #### Episodic/Intra-life hebbian update of the weights\n",
        "            if hebb_rule == 'A': \n",
        "                weights1_2, weights2_3, weights3_4 = hebbian_update_A(hebb_coeffs, weights1_2, weights2_3, weights3_4, o0, o1, o2, o3)\n",
        "            elif hebb_rule == 'AD':\n",
        "                weights1_2, weights2_3, weights3_4 = hebbian_update_AD(hebb_coeffs, weights1_2, weights2_3, weights3_4, o0, o1, o2, o3)\n",
        "            elif hebb_rule == 'AD_lr':\n",
        "                weights1_2, weights2_3, weights3_4 = hebbian_update_AD_lr(hebb_coeffs, weights1_2, weights2_3, weights3_4, o0, o1, o2, o3)\n",
        "            elif hebb_rule == 'ABC':\n",
        "                weights1_2, weights2_3, weights3_4 = hebbian_update_ABC(hebb_coeffs, weights1_2, weights2_3, weights3_4, o0, o1, o2, o3)\n",
        "            elif hebb_rule == 'ABC_lr':\n",
        "                weights1_2, weights2_3, weights3_4 = hebbian_update_ABC_lr(hebb_coeffs, weights1_2, weights2_3, weights3_4, o0, o1, o2, o3)\n",
        "            elif hebb_rule == 'ABCD':\n",
        "                weights1_2, weights2_3, weights3_4 = hebbian_update_ABCD(hebb_coeffs, weights1_2, weights2_3, weights3_4, o0, o1, o2, o3)\n",
        "            elif hebb_rule == 'ABCD_lr':\n",
        "                weights1_2, weights2_3, weights3_4 = hebbian_update_ABCD_lr_D_in(hebb_coeffs, weights1_2, weights2_3, weights3_4, o0, o1, o2, o3)\n",
        "            elif hebb_rule == 'ABCD_lr_D_out':\n",
        "                weights1_2, weights2_3, weights3_4 = hebbian_update_ABCD_lr_D_out(hebb_coeffs, weights1_2, weights2_3, weights3_4, o0, o1, o2, o3)\n",
        "            elif hebb_rule == 'ABCD_lr_D_in_and_out':\n",
        "                weights1_2, weights2_3, weights3_4 = hebbian_update_ABCD_lr_D_in_and_out(hebb_coeffs, weights1_2, weights2_3, weights3_4, o0, o1, o2, o3)\n",
        "            else:\n",
        "                raise ValueError('The provided Hebbian rule is not valid')\n",
        "                \n",
        "\n",
        "            # Normalise weights per layer\n",
        "            if normalised_weights == True:\n",
        "                (a, b, c) = (0, 1, 2) if not pixel_env else (2, 3, 4)\n",
        "                list(p.parameters())[a].data /= list(p.parameters())[a].__abs__().max()\n",
        "                list(p.parameters())[b].data /= list(p.parameters())[b].__abs__().max()\n",
        "                list(p.parameters())[c].data /= list(p.parameters())[c].__abs__().max()\n",
        "        \n",
        "            \n",
        "        env.close()\n",
        "\n",
        "    return rew_ep\n",
        "    # return max(rew_ep, 0)\n",
        "\n"
      ],
      "metadata": {
        "id": "M6mBtJMcmtBs"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}